Анализ 1. Сортировка выбором (Selection Sort)
Определение:
Алгоритм, который на каждой итерации находит минимальный элемент в неотсортированной части массива и помещает его в начало этой части.

Принцип работы:
Для массива [64, 25, 12, 22, 11]:

На первой итерации находится 11 и меняется с 64 → [11, 25, 12, 22, 64].
На второй — 12 меняется с 25 → [11, 12, 25, 22, 64], и так далее.
Временная сложность: O(n²)
Обоснование:
Внешний цикл выполняется n раз. Внутренний цикл на i-й итерации делает n − i − 1 сравнений. Общее число операций:

i=0
∑
n−1
​
 (n−i−1)= 
2
n(n−1)
​
 =O(n 
2
 )
Это справедливо для всех случаев — лучшего, среднего и худшего, так как поиск минимума всегда полный.

Анализ 2. Сортировка обменом (пузырьковая сортировка, Bubble Sort)
Определение:
Алгоритм, многократно проходящий по массиву и меняющий местами соседние элементы, если они нарушают порядок.

Принцип работы:
В массиве [64, 34, 25]:

Сравниваем 64 и 34 → меняем → [34, 64, 25].
Сравниваем 64 и 25 → меняем → [34, 25, 64].
Второй проход даёт [25, 34, 64].
Временная сложность: O(n²)
Обоснование:
Два вложенных цикла: внешний — n−1 итераций, внутренний — до n−i−1. Суммарно:

2
n(n−1)
​
 =O(n 
2
 )
Даже если массив отсортирован, базовая версия не оптимизирована и всё равно делает все проходы.

Анализ 3. Сортировка вставками (Insertion Sort)
Определение:
Алгоритм, строящий отсортированную последовательность по одному элементу, вставляя каждый новый элемент в правильное место среди уже отсортированных.

Принцип работы:
Для [12, 11, 13]:

11 сдвигается перед 12 → [11, 12, 13].
13 остаётся на месте.
Временная сложность: O(n²)
Обоснование:
В худшем случае (массив в обратном порядке) каждый элемент сравнивается со всеми предыдущими. Общее число сравнений:

0+1+2+⋯+(n−1)= 
2
n(n−1)
​
 =O(n 
2
 )
В лучшем случае — O(n), но в общем анализе указывается худший.

Анализ 4. Сортировка слиянием (Merge Sort)
Определение:
Рекурсивный алгоритм «разделяй и властвуй», делящий массив пополам, сортирующий подмассивы и сливающий их в один отсортированный.

Принцип работы:
[38, 27] → [38], [27] → [27, 38].

Временная сложность: O(n log n)
Обоснование:
Глубина рекурсии — log₂ n (деление пополам). На каждом уровне выполняется слияние всех n элементов → O(n) на уровень. Итого:

O(n)⋅O(logn)=O(nlogn)
Это верно для всех случаев, так как структура деления не зависит от данных.

Анализ 5. Сортировка Шелла (Shell Sort)
Определение:
Модификация сортировки вставками с использованием убывающих шагов (gap), сортирующая элементы на расстоянии gap.

Принцип работы:
Для [12, 34, 54, 2, 3]:

gap = 2: сортируются пары (12,54), (34,2), (54,3).
gap = 1: обычная вставка завершает сортировку.
Временная сложность: O(n²) (для последовательности n/2, n/4, …)
Обоснование:
При классической последовательности шагов возможны квадратичные сравнения. Например, если массив почти отсортирован, но смещён, вставка на последнем шаге может потребовать O(n²). Теоретически доказано, что для этой последовательности худший случай — O(n²).

Анализ 6. Быстрая сортировка (Quick Sort)
Определение:
Рекурсивный алгоритм, выбирающий опорный элемент и разделяющий массив на две части: ≤ опоры и > опоры.

Принцип работы:
Для [10, 7, 8, 9, 1, 5], опора 5 → левая часть [1], правая [10, 7, 8, 9] → рекурсия.

Временная сложность:

Средний случай: O(n log n)
Худший случай: O(n²)
Обоснование:
Если опора делит массив пополам — глубина log n, работа на уровне — n → O(n log n).
Если опора — крайний элемент в отсортированном массиве — деление на 1 и n−1 → глубина n, работа n + (n−1) + … = O(n²).
Анализ 7. Пирамидальная сортировка (Heap Sort)
Определение:
Алгоритм, использующий max-heap для извлечения максимальных элементов и помещения их в конец массива.

Принцип работы:
Из [12, 11, 13] строится куча [13, 11, 12], затем извлекается 13, 12, 11.

Временная сложность: O(n log n)
Обоснование:

Построение кучи: O(n) (благодаря bottom-up подходу).
Извлечение n элементов: каждое извлечение требует heapify — O(log n).
Итого: O(n) + O(n log n) = O(n log n).
Анализ 8. Последовательный (линейный) поиск
Определение:
Перебор элементов по порядку до нахождения цели.

Принцип работы:
В [3, 5, 2, 7] поиск 7 → проверка индексов 0,1,2,3 → найдено на 3.

Временная сложность: O(n)
Обоснование:
В худшем случае (элемента нет или он последний) проверяются все n элементов → линейная зависимость.

Анализ 9. Бинарный поиск
Определение:
Поиск в отсортированном массиве путём деления области поиска пополам.

Принцип работы:
В [1, 3, 5, 7, 9] поиск 7:

mid = 2 → 5 < 7 → идём вправо.
mid = 3 → 7 == 7 → найдено.
Временная сложность: O(log n)
Обоснование:
На каждом шаге область поиска уменьшается вдвое. Количество шагов до сужения до 1:

log 
2
​
 n
→ O(log n).

Анализ 10. Интерполирующий поиск
Определение:
Улучшенный бинарный поиск, предсказывающий позицию цели на основе равномерного распределения.

Принцип работы:
В [10, 20, 30, 40, 50] поиск 40:

pos=0+ 
50−10
(40−10)(4−0)
​
 =3
Временная сложность:

Лучший/средний (равномерное распределение): O(log log n)
Худший (неравномерное): O(n)
Обоснование:
Если данные равномерны, позиция предсказывается почти точно → очень быстрое сужение.
Если данные сгруппированы (например, экспоненциальный рост), формула даёт плохие оценки → может деградировать до линейного поиска.
Анализ 11. Поиск по Фибоначчи
Определение:
Алгоритм поиска в отсортированном массиве, использующий числа Фибоначчи для определения точек сравнения.

Принцип работы:
Для массива длины 11 используется F[7] = 13 ≥ 11. Сравнение происходит по индексу offset + F[m−2]. При несовпадении границы сдвигаются с использованием свойств последовательности Фибоначчи.

Временная сложность: O(log n)
Обоснование:
Числа Фибоначчи растут экспоненциально: F[k] ≈ φ^k / √5, где φ ≈ 1.618.
Следовательно, количество шагов до сужения области до 1 пропорционально log_φ n = O(log n).
