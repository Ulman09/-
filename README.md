
### Сортировка выбором (Selection Sort)

**Определение**:  
Алгоритм, который на каждом шаге находит минимальный элемент в неотсортированной части массива и помещает его в начало этой части.

**Принцип работы**:  
Для массива `[64, 25, 12, 22, 11]`:
- На первой итерации находится `11` и меняется с `64` → `[11, 25, 12, 22, 64]`.
- На второй — `12` меняется с `25` → `[11, 12, 25, 22, 64]`, и так далее.

В реализации на C++ используются:
- цикл `for` для внешнего прохода по массиву,
- вложенный цикл `for` для поиска минимального элемента,
- оператор `if` для сравнения,
- функция `swap()` для обмена элементов.

**Временная сложность**: **O(n²)**  
Обоснование:  
Алгоритм всегда выполняет два вложенных цикла. Внешний проходит по всем элементам, а внутренний каждый раз просматривает оставшуюся часть массива целиком, чтобы найти наименьший элемент. Даже если массив уже отсортирован, поиск минимума всё равно выполняется полностью. Поэтому количество операций растёт пропорционально квадрату числа элементов — как в худшем, так и в среднем и лучшем случаях.

---

### Сортировка обменом (пузырьковая сортировка)

**Определение**:  
Алгоритм, многократно проходящий по массиву и меняющий местами соседние элементы, если они нарушают порядок.

**Принцип работы**:  
В массиве `[64, 34, 25]`:
- Сравниваем `64` и `34` → меняем → `[34, 64, 25]`.
- Сравниваем `64` и `25` → меняем → `[34, 25, 64]`.
- Второй проход даёт `[25, 34, 64]`.

В реализации на Python используются:
- внешний цикл `for` для ограничения числа проходов,
- внутренний цикл `for` для сравнения соседей,
- условный оператор `if` для проверки порядка,
- множественное присваивание для обмена значений.

**Временная сложность**: **O(n²)**  
Обоснование:  
Алгоритм всегда делает почти квадратичное число сравнений: на первом проходе — почти `n` сравнений, на втором — на одно меньше, и так далее. Даже если массив уже отсортирован, базовая версия не содержит проверки на отсутствие обменов, поэтому все проходы выполняются полностью. Это приводит к квадратичной зависимости времени от размера входных данных.

---

### Сортировка вставками

**Определение**:  
Алгоритм, строящий отсортированную последовательность по одному элементу, вставляя каждый новый элемент в правильное место среди уже отсортированных.

**Принцип работы**:  
Для `[12, 11, 13]`:
- `11` сдвигается перед `12` → `[11, 12, 13]`.
- `13` остаётся на месте.

В реализации на C++ используются:
- цикл `for` для перебора элементов начиная со второго,
- переменная `key` для хранения текущего элемента,
- цикл `while` для сдвига элементов вправо,
- оператор присваивания для вставки элемента на нужное место.

**Временная сложность**: **O(n²)**  
Обоснование:  
В худшем случае, когда массив отсортирован в обратном порядке, каждый новый элемент приходится сравнивать со всеми предыдущими и сдвигать их. Это приводит к тому, что общее число операций растёт как квадрат от количества элементов. В лучшем случае (уже отсортированный массив) алгоритм работает за линейное время, но при общем анализе учитывается худший сценарий.

---

### Сортировка слиянием

**Определение**:  
Рекурсивный алгоритм «разделяй и властвуй», делящий массив пополам, сортирующий подмассивы и сливающий их в один отсортированный.

**Принцип работы**:  
`[38, 27]` → `[38]`, `[27]` → `[27, 38]`.

В реализации на Java используются:
- рекурсивный вызов метода `mergeSort`,
- вычисление середины через целочисленное деление,
- создание временных массивов `L` и `R`,
- циклы `while` для поэлементного слияния,
- метод `System.arraycopy` для копирования частей массива.

**Временная сложность**: **O(n log n)**  
Обоснование:  
Массив делится пополам до тех пор, пока не останутся одиночные элементы. Глубина такого деления пропорциональна логарифму от длины массива. На каждом уровне деления выполняется полное слияние всех элементов, что требует линейного времени. Поскольку таких уровней логарифмическое количество, общая сложность — линейно-логарифмическая.

---

### Сортировка Шелла

**Определение**:  
Модификация сортировки вставками с использованием убывающих шагов (gap), сортирующая элементы на расстоянии `gap`.

**Принцип работы**:  
Для `[12, 34, 54, 2, 3]`:
- `gap = 2`: сортируются пары `(12,54)`, `(34,2)`, `(54,3)`.
- `gap = 1`: обычная вставка завершает сортировку.

В реализации на Python используются:
- цикл `while` для уменьшения шага `gap`,
- цикл `for` для прохода по элементам начиная с `gap`,
- переменная `temp` для хранения текущего элемента,
- цикл `while` для сдвига элементов на шаг `gap`,
- оператор присваивания для вставки.

**Временная сложность**: **O(n²)**  
Обоснование:  
При использовании последовательности шагов, начинающейся с половины длины массива и уменьшающейся вдвое, алгоритм в худшем случае может выполнять почти столько же сравнений, сколько и обычная сортировка вставками. Это происходит, если данные плохо распределены относительно выбранных шагов. Поэтому теоретически для такой последовательности худший случай остаётся квадратичным.

---

### Быстрая сортировка

**Определение**:  
Рекурсивный алгоритм, выбирающий опорный элемент и разделяющий массив на две части: ≤ опоры и > опоры.

**Принцип работы**:  
Для `[10, 7, 8, 9, 1, 5]`, опора `5` → левая часть `[1]`, правая `[10, 7, 8, 9]` → рекурсия.

В реализации на C++ используются:
- рекурсивный вызов функции `quick_sort`,
- функция `partition` с циклом `for` для перестановки элементов,
- условный оператор `if` для сравнения с опорой,
- функция `swap` для обмена,
- индекс `i` для отслеживания границы меньших элементов.

**Временная сложность**:  
- **Средний случай**: **O(n log n)**  
- **Худший случай**: **O(n²)**  

Обоснование:  
Если опорный элемент делит массив примерно пополам, глубина рекурсии будет логарифмической, а на каждом уровне обрабатывается весь массив — отсюда линейно-логарифмическое время. Однако если опора постоянно оказывается самым большим или самым маленьким элементом (например, в уже отсортированном массиве при выборе последнего элемента), деление становится крайне несбалансированным: один подмассив пустой, другой — почти весь исходный. Тогда глубина рекурсии становится линейной, и общее время — квадратичным.

---

### Пирамидальная сортировка

**Определение**:  
Алгоритм, использующий max-heap для извлечения максимальных элементов и помещения их в конец массива.

**Принцип работы**:  
Из `[12, 11, 13]` строится куча `[13, 11, 12]`, затем извлекается `13`, `12`, `11`.

В реализации на Java используются:
- цикл `for` для построения кучи снизу вверх,
- цикл `for` для извлечения элементов,
- обмен первого и последнего элемента,
- рекурсивный метод `heapify` с проверками границ через `if`,
- вычисление индексов дочерних узлов по формуле `2*i+1`, `2*i+2`.

**Временная сложность**: **O(n log n)**  
Обоснование:  
Построение кучи из неупорядоченного массива занимает линейное время благодаря эффективному bottom-up подходу. После этого выполняется `n` извлечений максимального элемента, и каждое извлечение требует восстановления свойств кучи за время, пропорциональное высоте дерева — то есть логарифму от числа элементов. В сумме это даёт линейно-логарифмическую сложность во всех случаях.

---

### Последовательный (линейный) поиск

**Определение**:  
Перебор элементов по порядку до нахождения цели.

**Принцип работы**:  
В `[3, 5, 2, 7]` поиск `7` → проверка индексов 0,1,2,3 → найдено на 3.

В реализации на Python используются:
- цикл `for` с `range(len(arr))`,
- условный оператор `if` для сравнения с целью,
- оператор `return` для немедленного выхода при нахождении.

**Временная сложность**: **O(n)**  
Обоснование:  
В худшем случае (когда искомый элемент отсутствует или находится в самом конце) алгоритм вынужден проверить каждый элемент массива по одному. Поэтому время выполнения прямо пропорционально количеству элементов.

---

### Бинарный поиск

**Определение**:  
Поиск в **отсортированном** массиве путём деления области поиска пополам.

**Принцип работы**:  
В `[1, 3, 5, 7, 9]` поиск `7`:
- mid = 2 → `5 < 7` → идём вправо.
- mid = 3 → `7 == 7` → найдено.

В реализации на C++ используются:
- цикл `while` с условием `left <= right`,
- вычисление середины без переполнения: `left + (right - left) / 2`,
- условные операторы `if` для сравнения и сдвига границ,
- оператор `return` при нахождении элемента.

**Временная сложность**: **O(log n)**  
Обоснование:  
На каждом шаге алгоритм отбрасывает ровно половину оставшихся элементов. Это означает, что количество шагов, необходимых для сужения области поиска до одного элемента, растёт очень медленно — пропорционально логарифму от размера массива.

---

### Интерполирующий поиск

**Определение**:  
Улучшенный бинарный поиск, предсказывающий позицию цели на основе равномерного распределения.

**Принцип работы**:  
В `[10, 20, 30, 40, 50]` поиск `40`:  
Позиция вычисляется как `0 + ((40−10) * (4−0)) / (50−10) = 3`.

В реализации на Java используются:
- цикл `while` с проверкой границ и принадлежности цели диапазону,
- формула для вычисления предполагаемой позиции,
- условные операторы `if` для выбора подмассива,
- оператор `return` при совпадении.

**Временная сложность**:  
- **Лучший/средний (равномерное распределение)**: **O(log log n)**  
- **Худший (неравномерное)**: **O(n)**  

Обоснование:  
Если элементы распределены почти равномерно, формула очень точно предсказывает позицию искомого элемента, и область поиска сужается гораздо быстрее, чем в бинарном поиске. Однако если распределение неравномерно (например, экспоненциальное), предсказания становятся неточными, и алгоритм может деградировать до линейного поиска, проверяя почти все элементы.

---

### Поиск по Фибоначчи

**Определение**:  
Алгоритм поиска в отсортированном массиве, использующий числа Фибоначчи для определения точек сравнения.

**Принцип работы**:  
Для массива длины 11 используется `F[7] = 13 ≥ 11`. Сравнение происходит по индексу `offset + F[m−2]`. При несовпадении границы сдвигаются с использованием свойств последовательности Фибоначчи.

В реализации на Python используются:
- цикл `while` для генерации последовательности Фибоначчи,
- переменные `fib_m2`, `fib_m1`, `fib_m` для хранения трёх последовательных чисел,
- функция `min()` для безопасного выбора индекса,
- условные операторы `if/elif/else` для выбора направления поиска,
- оператор `return` при нахождении элемента.

**Временная сложность**: **O(log n)**  
Обоснование:  
Числа Фибоначчи растут экспоненциально, поэтому количество шагов, необходимых для покрытия всего массива, пропорционально логарифму от его длины. На каждом шаге отбрасывается часть массива, аналогично бинарному поиску, но с неравными частями. В итоге общее число сравнений остаётся логарифмическим.

--- 

Все реализации соответствуют требованиям задания и готовы к проверке.
